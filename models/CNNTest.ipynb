{
  "cells": [
    {
      "metadata": {
        "id": "hGyNfPt6YUJK",
        "colab_type": "text",
        "_uuid": "d05d37f24b27763ba25d3c79122b350703c8d7d0"
      },
      "cell_type": "markdown",
      "source": "# 种子杯\nv3 神经网络"
    },
    {
      "metadata": {
        "id": "2yzAgAffZ7Du",
        "colab_type": "code",
        "colab": {},
        "trusted": true,
        "_uuid": "09301f7e7385be9f9d0ec447b4f264af32d29fb7"
      },
      "cell_type": "code",
      "source": "FEATURE1_LEN = 60\nFEATURE2_LEN = 25\nFEATURE3_LEN = 100\nFEATURE4_LEN = 75\nEMBEDDING_DIM_CHAR = 256\nEMBEDDING_DIM_WORD = 256\nCHAR_DIM = 5036\nWORD_DIM = 82612",
      "execution_count": 42,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jEyB1Au1kz5G",
        "colab_type": "text",
        "_uuid": "8e0c64a7910e1cb8251408d751c2fc3cda0009a3"
      },
      "cell_type": "markdown",
      "source": "# 0. 初始"
    },
    {
      "metadata": {
        "id": "4tkd0gllYeVa",
        "colab_type": "code",
        "colab": {},
        "trusted": true,
        "_uuid": "f6dd6cf8038318bc72b8c0f8ec08298aef3956c6"
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nfrom collections import Counter  \nfrom sklearn.metrics import f1_score, accuracy_score, recall_score\n",
      "execution_count": 43,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H9ls0Rw1YRh_",
        "colab_type": "code",
        "colab": {},
        "trusted": true,
        "_uuid": "3bf68e7e60af9b9670262fdcdb2f1710a9689ab7"
      },
      "cell_type": "code",
      "source": "train = pd.read_csv(\"../input/train_a.txt\",sep='\\t') \nval = pd.read_csv(\"../input/valid_a.txt\",sep='\\t') \ntest = pd.read_csv(\"../input/test_a.txt\",sep='\\t') ",
      "execution_count": 44,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9TboRSuHY9j_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "fbd28320-4e63-4ced-f938-0c62b3cb0442",
        "trusted": true,
        "_uuid": "9785e5298c9b2b2ce6fdc4cc11e6b5f86c822a08"
      },
      "cell_type": "code",
      "source": "test.head()",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 45,
          "data": {
            "text/plain": "                            item_id   ...    cate3_id\n0  37392888990c22b43962210cdcd54214   ...         NaN\n1  4d1c0a2a597d0360d12f42a15875613d   ...         NaN\n2  78daa10add22fcdf33a8974bd1a6a2fa   ...         NaN\n3  f6f8abfe9a6c17e25d5820f38def1ab4   ...         NaN\n4  5d5e30daca51c0d66ba41bdd914d7982   ...         NaN\n\n[5 rows x 8 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>item_id</th>\n      <th>title_characters</th>\n      <th>title_words</th>\n      <th>description_characters</th>\n      <th>description_words</th>\n      <th>cate1_id</th>\n      <th>cate2_id</th>\n      <th>cate3_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>37392888990c22b43962210cdcd54214</td>\n      <td>c1208,c165,c94,c321,c15,c462,c557,c266,c207,c2...</td>\n      <td>w6093,w248,w384,w127,w5315,w2551,w16403,w53,w3...</td>\n      <td>c201,c434,c373,c27,c442,c303,c29,c2515,c295,c6...</td>\n      <td>w422,w3248,w1895,w2551,w16403,w83,w100,w13,w38...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4d1c0a2a597d0360d12f42a15875613d</td>\n      <td>c1675,c609,c677,c687,c290,c735,c15,c7,c1325,c6...</td>\n      <td>w65765,w352,w11,w4030,w127,w18,w3641,w2223,w12...</td>\n      <td>c1675,c609,c677,c687,c290,c735,c15,c7,c1325,c6...</td>\n      <td>w65765,w352,w11,w4030,w127,w18,w1,w2223,w24064...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>78daa10add22fcdf33a8974bd1a6a2fa</td>\n      <td>c539,c1699,c303,c111,c171,c164,c1031,c261,c24,...</td>\n      <td>w12808,w726,w80,w3421,w105,w682,w6081,w17,w173...</td>\n      <td>c201,c231,c33,c14,c86,c303,c1085,c1,c478,c132,...</td>\n      <td>w422,w176,w14,w157,w1421,w1,w205,w141,w196,w11...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>f6f8abfe9a6c17e25d5820f38def1ab4</td>\n      <td>c1208,c165,c217,c33,c15,c7,c266,c207,c291,c611...</td>\n      <td>w6093,w118,w11,w127,w25420,w31855,w1562,w18,w1...</td>\n      <td>c611,c611,c471,c299,c1732,c2346,c17,c9,c1,c20,...</td>\n      <td>w33577,w552,w31855,w18,w1,w61,w13349,w2,w33577...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5d5e30daca51c0d66ba41bdd914d7982</td>\n      <td>c2525,c314,c471,c299,c125,c264,c4,c4,c1987,c12...</td>\n      <td>w39351,w2892,w14069,w2577,w6,w4536,w36,w1784,w502</td>\n      <td>c2012,c19,c209,c125,c264,c4,c4,c3,c24,c97,c1,c...</td>\n      <td>w6967,w1156,w36787,w2,w4205,w1,w99,w310,w364,w...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "id": "feTNDZAFYjOb",
        "colab_type": "text",
        "_uuid": "d1429f881163e957898fc7caf5079e64d2c4a32a"
      },
      "cell_type": "markdown",
      "source": "# 1 数据预处理"
    },
    {
      "metadata": {
        "id": "9dSyva4yYrx7",
        "colab_type": "text",
        "_uuid": "0692b95eca2760b098acb7f415cc395954501431"
      },
      "cell_type": "markdown",
      "source": "## 1.1 获取y编号 "
    },
    {
      "metadata": {
        "id": "Jwws-WOmYcd-",
        "colab_type": "code",
        "colab": {},
        "trusted": true,
        "_uuid": "7a329df6dd5445f8170d13a37206b6712b2c4955"
      },
      "cell_type": "code",
      "source": "cate1 = list(train['cate1_id'].unique())\ncate2 = list(train['cate2_id'].unique())\ncate3 = list(train['cate3_id'].unique())\ntrainLen = len(train)\nvalLen = len(val)\ntestLen = len(test)\n# 获取类目树\nTree = {}\nfor item1 in cate1:\n    cate2List = train[train['cate1_id'] == item1]['cate2_id'].unique()\n    cate2Dic = {}\n    for item2 in cate2List:\n        cate3List = train[train['cate2_id'] == item2]['cate3_id'].unique()\n        cate2Dic[item2] = list(cate3List)\n    Tree[item1] = cate2Dic\n",
      "execution_count": 46,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZFTO_2BMY1n6",
        "colab_type": "text",
        "_uuid": "74f9208315b7fdc243c55f6162907f31933f9e72"
      },
      "cell_type": "markdown",
      "source": "## 1.2 构建字典"
    },
    {
      "metadata": {
        "id": "R-wJUtyFlePn",
        "colab_type": "text",
        "_uuid": "75f02f5007d5f4458dba8424984091c23040fd40"
      },
      "cell_type": "markdown",
      "source": "### 1.2.1 四个属性分析"
    },
    {
      "metadata": {
        "id": "xxfQShYnTXf_",
        "colab_type": "text",
        "_uuid": "f6c2618fa5dbad3cc96427be87cb9c6e5d9ec35c"
      },
      "cell_type": "markdown",
      "source": "#### 1.2.1.1 标题字\nsort_tc 4001个\n\n60为界限 0.9999075141218822"
    },
    {
      "metadata": {
        "id": "j5YHmuMPasjK",
        "colab_type": "code",
        "colab": {},
        "trusted": true,
        "_uuid": "4867fa701da541da64bb438737962416a2951333"
      },
      "cell_type": "code",
      "source": "# 测试 先只考虑标题字\nall_word = []\nfor item in train['title_characters']:\n    for word in item.split(','):\n        all_word.append(word)\nfor item in val['title_characters']:\n    for word in item.split(','):\n        all_word.append(word)\nfor item in test['title_characters']:\n    for word in item.split(','):\n        all_word.append(word)\ntitle_characters = dict(Counter(all_word))\nsort_tc = sorted(title_characters.items(),key = lambda x:x[1],reverse = True)\n\ndel all_word,title_characters",
      "execution_count": 47,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZPUl8GehVBeK",
        "colab_type": "text",
        "_uuid": "196332c20223626ff16a071bcb1fb2faf3631044"
      },
      "cell_type": "markdown",
      "source": "#### 1.2.1.2 标题词\nsort_tw 50655个\n\n25界限 0.98084830893129"
    },
    {
      "metadata": {
        "id": "VaOOub2ZU8zU",
        "colab_type": "code",
        "colab": {},
        "trusted": true,
        "_uuid": "564285b02584236995fc46384d766f36f16cc073"
      },
      "cell_type": "code",
      "source": "# 标题词\nall_word = []\nfor item in train['title_words']:\n    for word in item.split(','):\n        all_word.append(word)\nfor item in val['title_words']:\n    for word in item.split(','):\n        all_word.append(word)\nfor item in test['title_words']:\n    for word in item.split(','):\n        all_word.append(word)\ntitle_words = dict(Counter(all_word))\nsort_tw = sorted(title_words.items(),key = lambda x:x[1],reverse = True)\n\ndel all_word,title_words",
      "execution_count": 48,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LaPWQO3HVMyU",
        "colab_type": "text",
        "_uuid": "3f04e5f50164352c6f8075ab9c14232612b06762"
      },
      "cell_type": "markdown",
      "source": "#### 1.2.1.3 描述字\nsort_dc 4805个\n\n100: 0.9035372291230918"
    },
    {
      "metadata": {
        "id": "LLnH0pBOVRJ7",
        "colab_type": "code",
        "colab": {},
        "trusted": true,
        "_uuid": "2250da4497b3117aab290ed280128c841abd5e6a"
      },
      "cell_type": "code",
      "source": "# 描述字\nall_word = []\nfor item in train['description_characters']:\n    for word in item.split(','):\n        all_word.append(word)\nfor item in val['description_characters']:\n    for word in item.split(','):\n        all_word.append(word)\nfor item in test['description_characters']:\n    for word in item.split(','):\n        all_word.append(word)\ndescription_characters = dict(Counter(all_word))\nsort_dc = sorted(description_characters.items(),key = lambda x:x[1],reverse = True)\n\ndel all_word,description_characters",
      "execution_count": 49,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YmamMQNZVaTa",
        "colab_type": "text",
        "_uuid": "e07068c0b8d9a185fb0a88801d82d240f1d3de0c"
      },
      "cell_type": "markdown",
      "source": "#### 1.2.1.4 描述词\nsort_dw 64357个\n\n75: 0.9666339408944092,"
    },
    {
      "metadata": {
        "id": "Gu_FlpVxVed5",
        "colab_type": "code",
        "colab": {},
        "trusted": true,
        "_uuid": "b8e06805724eafef31bf4292b0e91ff9036fac38"
      },
      "cell_type": "code",
      "source": "# 描述词\nall_word = []\nfor item in train['description_words']:\n    for word in item.split(','):\n        all_word.append(word)\nfor item in val['description_words']:\n    for word in item.split(','):\n        all_word.append(word)\nfor item in test['description_words']:\n    for word in item.split(','):\n        all_word.append(word)\ndescription_words = dict(Counter(all_word))\nsort_dw = sorted(description_words.items(),key = lambda x:x[1],reverse = True)\n\ndel all_word,description_words",
      "execution_count": 50,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zaex4L0Olts-",
        "colab_type": "text",
        "_uuid": "de55d88658f13092d29fdac4ae4f016b3dda67b0"
      },
      "cell_type": "markdown",
      "source": "### 1.2.2 字词分析\n"
    },
    {
      "metadata": {
        "id": "PgWqWYxKl8Aa",
        "colab_type": "code",
        "colab": {},
        "trusted": true,
        "_uuid": "e058732b198b53c50b0ba76bd907a830df786c66"
      },
      "cell_type": "code",
      "source": "# 字 5036\nall_word = []\nfor item in train['title_characters']:\n    for word in item.split(','):\n        all_word.append(word)\nfor item in val['title_characters']:\n    for word in item.split(','):\n        all_word.append(word)\nfor item in test['title_characters']:\n    for word in item.split(','):\n        all_word.append(word)\nfor item in train['description_characters']:\n    for word in item.split(','):\n        all_word.append(word)\nfor item in val['description_characters']:\n    for word in item.split(','):\n        all_word.append(word)\nfor item in test['description_characters']:\n    for word in item.split(','):\n        all_word.append(word)\ncharacters = dict(Counter(all_word))\nsort_c = sorted(characters.items(),key = lambda x:x[1],reverse = True)\n\ndel all_word,characters",
      "execution_count": 51,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VF6eu5TdlQpa",
        "colab_type": "code",
        "colab": {},
        "trusted": true,
        "_uuid": "37e3854757486fcfc7141188adec0b56f9d15ea1"
      },
      "cell_type": "code",
      "source": "# 词 82612\nall_word = []\nfor item in train['title_words']:\n    for word in item.split(','):\n        all_word.append(word)\nfor item in val['title_words']:\n    for word in item.split(','):\n        all_word.append(word)\nfor item in test['title_words']:\n    for word in item.split(','):\n        all_word.append(word)\nfor item in train['description_words']:\n    for word in item.split(','):\n        all_word.append(word)\nfor item in val['description_words']:\n    for word in item.split(','):\n        all_word.append(word)\nfor item in test['description_words']:\n    for word in item.split(','):\n        all_word.append(word)\nwords_ = dict(Counter(all_word))\nsort_w = sorted(words_.items(),key = lambda x:x[1],reverse = True)\n\ndel all_word,words_",
      "execution_count": 52,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V0h0aVA_VSKF",
        "colab_type": "text",
        "_uuid": "31a8654150b18d401fa244c218bb1866c8650907"
      },
      "cell_type": "markdown",
      "source": "### 1.2.3 构建字典"
    },
    {
      "metadata": {
        "id": "o9YSxmVVcHfd",
        "colab_type": "code",
        "colab": {},
        "trusted": true,
        "_uuid": "b926b65785cd6955bd78b7d057a56653cce5e1de"
      },
      "cell_type": "code",
      "source": "# 词典 字符-》id编号\nword_id_char = {}\nfor i,item in enumerate(sort_c):\n  word_id_char[item[0]]=i+1\n  \nword_id_word = {}\nfor i,item in enumerate(sort_w):\n  word_id_word[item[0]]=i+1",
      "execution_count": 53,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WIyrDuGMa1OK",
        "colab_type": "code",
        "colab": {},
        "trusted": true,
        "_uuid": "3c757094a7b452e0c8fca45736dc7a76faec3dfb"
      },
      "cell_type": "code",
      "source": "# # 选择合适长度\n# total_len = [len(item.split(',')) for item in train['description_words']]\n# total_len_result= dict(Counter(total_len))\n# total = 0\n# for item in total_len_result:\n#   total+=total_len_result[item]\n# for item in range(1,120):\n#   if item == 1:\n#     total_len_result[item] = total_len_result[item]/total\n#   else:\n#     total_len_result[item] = total_len_result[item]/total + total_len_result[item-1]\n# total_len_result",
      "execution_count": 54,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_5z2BAQEcsqQ",
        "colab_type": "text",
        "_uuid": "66004489617ea58ed92cc5d593823a526bea5d9b"
      },
      "cell_type": "markdown",
      "source": "## 1.3 构建X，y"
    },
    {
      "metadata": {
        "id": "VIgbtx9_bbLh",
        "colab_type": "code",
        "colab": {},
        "trusted": true,
        "_uuid": "770f8f82d168ee458356228f687325ec72e52d10"
      },
      "cell_type": "code",
      "source": "def getX(columnName,featureNum,word_id):\n  train_X = np.zeros((trainLen,featureNum))\n  for i in range(trainLen):\n    words = train[columnName][i].split(',')\n    wordsLen = len(words)\n    for j in range(min(featureNum,wordsLen)):\n      train_X[i][j] = word_id[words[j]]\n\n  val_X = np.zeros((valLen,featureNum))\n  for i in range(valLen):\n    words = val[columnName][i].split(',')\n    wordsLen = len(words)\n    for j in range(min(featureNum,wordsLen)):\n      val_X[i][j] = word_id[words[j]]\n      \n  test_X = np.zeros((testLen,featureNum))\n  for i in range(testLen):\n    words = test[columnName][i].split(',')\n    wordsLen = len(words)\n    for j in range(min(featureNum,wordsLen)):\n      test_X[i][j] = word_id[words[j]]\n  print('finish')\n  return train_X,val_X,test_X",
      "execution_count": 55,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V0LkHttWcPvR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "8d3a47ca-bcde-4e24-aedc-e6ea4c442a21",
        "trusted": true,
        "_uuid": "c31ead140ab47e5b40cd76d0942ec526f68c2428"
      },
      "cell_type": "code",
      "source": "train_X1,val_X1,test_X1 = getX('title_characters',FEATURE1_LEN,word_id_char)\ntrain_X2,val_X2,test_X2 = getX('title_words',FEATURE2_LEN,word_id_word)\ntrain_X3,val_X3,test_X3 = getX('description_characters',FEATURE3_LEN,word_id_char)\ntrain_X4,val_X4,test_X4 = getX('description_words',FEATURE4_LEN,word_id_word)",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": "finish\nfinish\nfinish\nfinish\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3OdZVIIKbp6_",
        "colab_type": "code",
        "colab": {},
        "trusted": true,
        "_uuid": "f53bd757be78e70e03288a1ca2861ee354cd2bff"
      },
      "cell_type": "code",
      "source": "# 编号版\ntrain_y1 = [cate1.index(item) for item in train['cate1_id'].tolist()]\ntrain_y2 = [cate2.index(item) for item in train['cate2_id'].tolist()]\ntrain_y3 = [cate3.index(item) for item in train['cate3_id'].tolist()]\n\nval_y1 = [cate1.index(item) for item in val['cate1_id'].tolist()]\nval_y2 = [cate2.index(item) for item in val['cate2_id'].tolist()]\nval_y3 = [cate3.index(item) for item in val['cate3_id'].tolist()]",
      "execution_count": 57,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SpMvhZSknaf-",
        "colab_type": "code",
        "colab": {},
        "trusted": true,
        "_uuid": "ce62e2a552cc2f63e9949c7070e1026241fd6e60",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "# 独热版\nfrom sklearn.preprocessing import OneHotEncoder\n\nohe1 = OneHotEncoder()\nohe1.fit(np.array(train_y1).reshape(-1,1))\n\ntrain_y1_hot = ohe1.transform(np.array(train_y1).reshape(-1,1)).toarray()\nval_y1_hot = ohe1.transform(np.array(val_y1).reshape(-1,1)).toarray()\n\nohe2 = OneHotEncoder()\nohe2.fit(np.array(train_y2).reshape(-1,1))\n\ntrain_y2_hot = ohe2.transform(np.array(train_y2).reshape(-1,1)).toarray()\nval_y2_hot = ohe2.transform(np.array(val_y2).reshape(-1,1)).toarray()\n\nohe3 = OneHotEncoder()\nohe3.fit(np.array(train_y3).reshape(-1,1))\n\ntrain_y3_hot = ohe3.transform(np.array(train_y3).reshape(-1,1)).toarray()\nval_y3_hot = ohe3.transform(np.array(val_y3).reshape(-1,1)).toarray()",
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\nIf you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\nIn case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n  warnings.warn(msg, FutureWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\nIf you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\nIn case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n  warnings.warn(msg, FutureWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\nIf you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\nIn case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n  warnings.warn(msg, FutureWarning)\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "3KvHw5JQh0dw",
        "colab_type": "text",
        "_uuid": "e1c218b845740bac6e5ac64d353e4ba06f676ab3"
      },
      "cell_type": "markdown",
      "source": "# 2. 构建网络"
    },
    {
      "metadata": {
        "id": "1XavBBCfVr87",
        "colab_type": "text",
        "_uuid": "a680bca6b0306d7132f4cc4557671acbca78bd68"
      },
      "cell_type": "markdown",
      "source": "## 2.1 辅助函数"
    },
    {
      "metadata": {
        "id": "MzSGqB_chv7l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cca30d54-6bf4-4cb0-a152-bace0770d098",
        "trusted": true,
        "_uuid": "f7ddefe526d4f6c7eb1df6eca93ba8050fd14077"
      },
      "cell_type": "code",
      "source": "import keras\nimport tensorflow as tf\nfrom keras import backend as K\nfrom keras.models import Sequential,Model\nfrom keras.layers import Dense, Activation, Dropout,Input,Embedding,LSTM,Bidirectional\nfrom keras.callbacks import Callback,EarlyStopping\nfrom keras.optimizers import Adam,Adamax\nfrom keras import regularizers\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.advanced_activations import LeakyReLU",
      "execution_count": 59,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k7GEK1qtVuE7",
        "colab_type": "code",
        "colab": {},
        "trusted": true,
        "_uuid": "fcba25961d15bff9e50e18f3f27d23462c0829a0"
      },
      "cell_type": "code",
      "source": "# 清空图\ndef reset_tf_session():\n    curr_session = tf.get_default_session()\n    # close current session\n    if curr_session is not None:\n        curr_session.close()\n    # reset graph\n    K.clear_session()\n    # create new session\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    s = tf.InteractiveSession(config=config)\n    K.set_session(s)\n    return s",
      "execution_count": 60,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fxh_BgRy0EpI",
        "colab_type": "code",
        "colab": {},
        "trusted": true,
        "_uuid": "5076dbc135bd1620f05478928c002973f603c94b"
      },
      "cell_type": "code",
      "source": "# 自定义获取val集F1\nclass GetF1(Callback):\n  def on_train_begin(self, logs={}):\n    self.f1 = []\n    self.f2 = []\n    self.f3 = []\n\n  def on_epoch_end(self, epoch, logs={}):\n    v1,v2,v3 = measureVal(model)\n    self.f1.append(v1)\n    self.f2.append(v2)\n    self.f3.append(v3)\n    return\n\ngetF1 = GetF1()\n\n# 保存\nmodelSave = keras.callbacks.ModelCheckpoint(filepath='weights.{epoch:02d}-{val_loss:.2f}.hdf5')\n\n# 早停\nearly_stopping = EarlyStopping(monitor='val_loss', patience=2)",
      "execution_count": 61,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vPoaSdn5XQDf",
        "colab_type": "code",
        "colab": {},
        "trusted": true,
        "_uuid": "cac77af1243941c2862cd4e74f2a0e6c166c0d60"
      },
      "cell_type": "code",
      "source": "# 解独热编码\ndef deOneHot(result,cate=None):\n  '''\n  如果有cate，则根据cate还原成原分类编号\n  '''\n  result_list = []\n  if cate == None:\n    for i,item in enumerate(result):\n      result_list.append(list(result[i]).index(max(item)))\n  else:\n    for i,item in enumerate(result):\n      result_list.append(cate[list(result[i]).index(max(item))])    \n  return result_list\n",
      "execution_count": 62,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lu2JNlj09I98",
        "colab_type": "code",
        "colab": {},
        "trusted": true,
        "_uuid": "09e1603cfe302471dd2dfba433db7b93efbed37b"
      },
      "cell_type": "code",
      "source": "def measureVal(model):\n  '''\n  通过val集 预测模型f1效果\n  '''\n  result1,result2,result3 = model.predict([val_X1,val_X2,val_X3,val_X4])\n  result_list1 = deOneHot(result1)\n  result_list2 = deOneHot(result2)\n  result_list3 = deOneHot(result3)\n  v1 = f1_score(result_list1, val_y1, average='macro')\n  v2 = f1_score(result_list2, val_y2, average='macro')\n  v3 = f1_score(result_list3, val_y3, average='macro')\n  print('cate1:',v1)\n  print('cate2:',v2)\n  print('cate3:',v3)\n  print('total:',(v1*0.1+v2*0.3+v3*0.6))\n  return v1,v2,v3\n\n\ndef predictTest(model,saveName = None):\n  '''\n  预测、保存test集结果\n  '''\n  result1,result2,result3 = model.predict([test_X1,test_X2,test_X3,test_X4])\n  result_list1 = deOneHot(result1,cate1)\n  result_list2 = deOneHot(result2,cate2)\n  result_list3 = deOneHot(result3,cate3)\n  test.loc[:,'cate1_id']=result_list1\n  test.loc[:,'cate2_id']=result_list2\n  test.loc[:,'cate3_id']=result_list3\n  if saveName != None:\n    test[['item_id','cate1_id','cate2_id','cate3_id']].to_csv(saveName,sep=\"\\t\",index=False)",
      "execution_count": 63,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DwaucbOUS_zg",
        "colab_type": "text",
        "_uuid": "593582a451b495a06e074eeb529b201b1f5bf83d"
      },
      "cell_type": "markdown",
      "source": "### 2.2 构建网络"
    },
    {
      "metadata": {
        "id": "0W2KKTMJuRW7",
        "colab_type": "code",
        "colab": {},
        "trusted": true,
        "_uuid": "7fa7dc06fd96cd971f4cf424709bca5cc25a0f6e"
      },
      "cell_type": "code",
      "source": " #s =  reset_tf_session()  # 清空之前的图\n\ninput_tc = Input(shape=(FEATURE1_LEN,), dtype='int32', name='input_tc')\ninput_tw = Input(shape=(FEATURE2_LEN,), dtype='int32', name='input_tw')\ninput_dc = Input(shape=(FEATURE3_LEN,), dtype='int32', name='input_dc')\ninput_dw = Input(shape=(FEATURE4_LEN,), dtype='int32', name='input_dw')\nembedding_char = Embedding(output_dim=EMBEDDING_DIM_CHAR, input_dim=CHAR_DIM)\nembedding_word = Embedding(output_dim=EMBEDDING_DIM_WORD, input_dim=WORD_DIM)\nconv_1=keras.layers.Conv1D(filters=128,kernel_size=4,strides=2,padding='same',activation='tanh')(embedding_char(input_tc))\nmaxpool_1=keras.layers.MaxPooling1D(pool_size=4)(conv_1)\nflat_1=keras.layers.Flatten()(maxpool_1)\nconv_2=keras.layers.Conv1D(filters=128,kernel_size=4,strides=2,padding='same',activation='tanh')(embedding_char(input_dc))\nmaxpool_2=keras.layers.MaxPooling1D(pool_size=4)(conv_2)\nflat_2=keras.layers.Flatten()(maxpool_2)\nconv_3=keras.layers.Conv1D(filters=128,kernel_size=4,strides=2,padding='same',activation='tanh')(embedding_word(input_tw))\nmaxpool_3=keras.layers.MaxPooling1D(pool_size=4)(conv_3)\nflat_3=keras.layers.Flatten()(maxpool_3)\nconv_4=keras.layers.Conv1D(filters=128,kernel_size=4,strides=2,padding='same',activation='tanh')(embedding_word(input_dw))\nmaxpool_4=keras.layers.MaxPooling1D(pool_size=4)(conv_4)\nflat_4=keras.layers.Flatten()(maxpool_4)\nmerge_layer = keras.layers.concatenate(([flat_1,flat_2,flat_3,flat_4]))\ndense_0 = Dense(1024,activation=None)(merge_layer)\ndense_0 = BatchNormalization(momentum=0.9, epsilon=10**-8)(dense_0)\ndense_0 = LeakyReLU()(dense_0)\ndense_0 = Dense(512,activation=None)(dense_0)\ndense_0 = BatchNormalization(momentum=0.9, epsilon=10**-8)(dense_0)\ndense_0 = LeakyReLU()(dense_0)\ndense_1 = Dense(64,activation=None)(dense_0)\ndense_1 = LeakyReLU()(dense_1)\ndense_2 = Dense(128,activation=None)(dense_0)\ndense_2 = LeakyReLU()(dense_2)\ndense_3 = Dense(256,activation=None)(dense_0)\ndense_3 = LeakyReLU()(dense_3)\n\noutput_1 = Dense(10, activation='softmax', name='output_1')(dense_1)\n\nmerge_layer2 = keras.layers.concatenate([output_1,dense_2])\noutput_2 = Dense(64, activation='softmax', name='output_2')(merge_layer2)\n\nmerge_layer3 = keras.layers.concatenate([output_1,output_2,dense_3])\noutput_3 = Dense(125, activation='softmax', name='output_3')(merge_layer3)",
      "execution_count": 64,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P4n-4nh4zOUS",
        "colab_type": "code",
        "colab": {},
        "trusted": true,
        "_uuid": "9ea767e4cf9d29c718b74e1c7c1a19bc2bcbf8bb"
      },
      "cell_type": "code",
      "source": "model = Model(inputs=[input_tc,input_tw,input_dc,input_dw], outputs=[output_1,output_2,output_3])",
      "execution_count": 65,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wQOyCQMdCyKy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 985
        },
        "outputId": "eeb0dd58-bb54-4b61-fd1b-ba730c295bdd",
        "trusted": true,
        "_uuid": "2b77e451b20ec33b46e5abd03e9e8de68124a624",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "model.summary()",
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": "__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_tc (InputLayer)           (None, 60)           0                                            \n__________________________________________________________________________________________________\ninput_dc (InputLayer)           (None, 100)          0                                            \n__________________________________________________________________________________________________\ninput_tw (InputLayer)           (None, 25)           0                                            \n__________________________________________________________________________________________________\ninput_dw (InputLayer)           (None, 75)           0                                            \n__________________________________________________________________________________________________\nembedding_5 (Embedding)         multiple             1289216     input_tc[0][0]                   \n                                                                 input_dc[0][0]                   \n__________________________________________________________________________________________________\nembedding_6 (Embedding)         multiple             21148672    input_tw[0][0]                   \n                                                                 input_dw[0][0]                   \n__________________________________________________________________________________________________\nconv1d_9 (Conv1D)               (None, 30, 128)      131200      embedding_5[0][0]                \n__________________________________________________________________________________________________\nconv1d_10 (Conv1D)              (None, 50, 128)      131200      embedding_5[1][0]                \n__________________________________________________________________________________________________\nconv1d_11 (Conv1D)              (None, 13, 128)      131200      embedding_6[0][0]                \n__________________________________________________________________________________________________\nconv1d_12 (Conv1D)              (None, 38, 128)      131200      embedding_6[1][0]                \n__________________________________________________________________________________________________\nmax_pooling1d_9 (MaxPooling1D)  (None, 7, 128)       0           conv1d_9[0][0]                   \n__________________________________________________________________________________________________\nmax_pooling1d_10 (MaxPooling1D) (None, 12, 128)      0           conv1d_10[0][0]                  \n__________________________________________________________________________________________________\nmax_pooling1d_11 (MaxPooling1D) (None, 3, 128)       0           conv1d_11[0][0]                  \n__________________________________________________________________________________________________\nmax_pooling1d_12 (MaxPooling1D) (None, 9, 128)       0           conv1d_12[0][0]                  \n__________________________________________________________________________________________________\nflatten_9 (Flatten)             (None, 896)          0           max_pooling1d_9[0][0]            \n__________________________________________________________________________________________________\nflatten_10 (Flatten)            (None, 1536)         0           max_pooling1d_10[0][0]           \n__________________________________________________________________________________________________\nflatten_11 (Flatten)            (None, 384)          0           max_pooling1d_11[0][0]           \n__________________________________________________________________________________________________\nflatten_12 (Flatten)            (None, 1152)         0           max_pooling1d_12[0][0]           \n__________________________________________________________________________________________________\nconcatenate_7 (Concatenate)     (None, 3968)         0           flatten_9[0][0]                  \n                                                                 flatten_10[0][0]                 \n                                                                 flatten_11[0][0]                 \n                                                                 flatten_12[0][0]                 \n__________________________________________________________________________________________________\ndense_11 (Dense)                (None, 1024)         4064256     concatenate_7[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_11 (BatchNo (None, 1024)         4096        dense_11[0][0]                   \n__________________________________________________________________________________________________\nleaky_re_lu_11 (LeakyReLU)      (None, 1024)         0           batch_normalization_11[0][0]     \n__________________________________________________________________________________________________\ndense_12 (Dense)                (None, 512)          524800      leaky_re_lu_11[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_12 (BatchNo (None, 512)          2048        dense_12[0][0]                   \n__________________________________________________________________________________________________\nleaky_re_lu_12 (LeakyReLU)      (None, 512)          0           batch_normalization_12[0][0]     \n__________________________________________________________________________________________________\ndense_13 (Dense)                (None, 64)           32832       leaky_re_lu_12[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_13 (BatchNo (None, 64)           256         dense_13[0][0]                   \n__________________________________________________________________________________________________\ndense_14 (Dense)                (None, 128)          65664       leaky_re_lu_12[0][0]             \n__________________________________________________________________________________________________\nleaky_re_lu_13 (LeakyReLU)      (None, 64)           0           batch_normalization_13[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_14 (BatchNo (None, 128)          512         dense_14[0][0]                   \n__________________________________________________________________________________________________\noutput_1 (Dense)                (None, 10)           650         leaky_re_lu_13[0][0]             \n__________________________________________________________________________________________________\nleaky_re_lu_14 (LeakyReLU)      (None, 128)          0           batch_normalization_14[0][0]     \n__________________________________________________________________________________________________\ndense_15 (Dense)                (None, 256)          131328      leaky_re_lu_12[0][0]             \n__________________________________________________________________________________________________\nconcatenate_8 (Concatenate)     (None, 138)          0           output_1[0][0]                   \n                                                                 leaky_re_lu_14[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_15 (BatchNo (None, 256)          1024        dense_15[0][0]                   \n__________________________________________________________________________________________________\noutput_2 (Dense)                (None, 64)           8896        concatenate_8[0][0]              \n__________________________________________________________________________________________________\nleaky_re_lu_15 (LeakyReLU)      (None, 256)          0           batch_normalization_15[0][0]     \n__________________________________________________________________________________________________\nconcatenate_9 (Concatenate)     (None, 330)          0           output_1[0][0]                   \n                                                                 output_2[0][0]                   \n                                                                 leaky_re_lu_15[0][0]             \n__________________________________________________________________________________________________\noutput_3 (Dense)                (None, 125)          41375       concatenate_9[0][0]              \n==================================================================================================\nTotal params: 27,840,425\nTrainable params: 27,836,457\nNon-trainable params: 3,968\n__________________________________________________________________________________________________\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KokOaEubV2uo",
        "colab_type": "code",
        "colab": {},
        "trusted": true,
        "_uuid": "2eedbbd3939a0d1b7d8389b0da5eec80165cce92"
      },
      "cell_type": "code",
      "source": "model.compile(loss='categorical_crossentropy',\n              loss_weights={'output_1': 0.1, 'output_2': 0.3, 'output_3': 0.8},\n              optimizer=Adamax(epsilon=10**-8, decay=0.01),\n              metrics=['accuracy'])\n\n",
      "execution_count": 67,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0Xmvmg2oTlzS",
        "colab_type": "code",
        "colab": {},
        "trusted": true,
        "_uuid": "45e9a57ee189c9cfad8c74d997fd962baf9c5d6b"
      },
      "cell_type": "code",
      "source": "START_EPOCH = 0\nEPOCH = 10",
      "execution_count": 68,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Dkxnd2og9Zlw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "1a309c00-40ac-464b-cce3-2101b4c7da49",
        "trusted": true,
        "_uuid": "086e30c6827aa4ce7905791ea56b2ae4dbbeca2b",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "History = model.fit([train_X1,train_X2,train_X3,train_X4], [train_y1_hot,train_y2_hot,train_y3_hot], \n                    batch_size=256,\n                    epochs=START_EPOCH+EPOCH,                    \n                    shuffle=True, \n                    callbacks=[early_stopping,modelSave,getF1],\n                    validation_data=([val_X1,val_X2,val_X3,val_X4], [val_y1_hot,val_y2_hot,val_y3_hot]),\n                    initial_epoch=START_EPOCH)\n\nprint(History)\n# model.save('RNN_2_10.h5')\n# #你想要导出的文件的名字\n# uploaded = drive.CreateFile({'title': 'RNN_2_10.h5'})\n# #改为之前生成文件的名字\n# uploaded.SetContentFile('RNN_2_10.h5')\n# uploaded.Upload()\n# print('Uploaded file with ID {}'.format(uploaded.get('id')))",
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Train on 140562 samples, validate on 10580 samples\nEpoch 1/10\n140562/140562 [==============================] - 408s 3ms/step - loss: 1.0346 - output_1_loss: 0.2358 - output_2_loss: 0.6928 - output_3_loss: 1.0040 - output_1_acc: 0.9391 - output_2_acc: 0.8374 - output_3_acc: 0.7505 - val_loss: 0.5964 - val_output_1_loss: 0.1055 - val_output_2_loss: 0.3468 - val_output_3_loss: 0.6023 - val_output_1_acc: 0.9765 - val_output_2_acc: 0.9095 - val_output_3_acc: 0.8336\ncate1: 0.9592838455631686\ncate2: 0.8624436265435199\ncate3: 0.7957229883272229\ntotal: 0.8320952655157066\nEpoch 2/10\n140562/140562 [==============================] - 400s 3ms/step - loss: 0.3533 - output_1_loss: 0.0705 - output_2_loss: 0.2117 - output_3_loss: 0.3535 - output_1_acc: 0.9847 - output_2_acc: 0.9469 - output_3_acc: 0.9043 - val_loss: 0.5465 - val_output_1_loss: 0.0901 - val_output_2_loss: 0.3053 - val_output_3_loss: 0.5573 - val_output_1_acc: 0.9785 - val_output_2_acc: 0.9166 - val_output_3_acc: 0.8394\ncate1: 0.963040126270983\ncate2: 0.8790232887061689\ncate3: 0.8036497220947819\ntotal: 0.8422008324958181\nEpoch 3/10\n140562/140562 [==============================] - 399s 3ms/step - loss: 0.2378 - output_1_loss: 0.0505 - output_2_loss: 0.1449 - output_3_loss: 0.2366 - output_1_acc: 0.9897 - output_2_acc: 0.9663 - output_3_acc: 0.9410 - val_loss: 0.5403 - val_output_1_loss: 0.0823 - val_output_2_loss: 0.2960 - val_output_3_loss: 0.5541 - val_output_1_acc: 0.9797 - val_output_2_acc: 0.9179 - val_output_3_acc: 0.8395\ncate1: 0.9652719943121868\ncate2: 0.88214421407716\ncate3: 0.806430975947377\ntotal: 0.8450290492227929\nEpoch 4/10\n140562/140562 [==============================] - 404s 3ms/step - loss: 0.1739 - output_1_loss: 0.0405 - output_2_loss: 0.1091 - output_3_loss: 0.1714 - output_1_acc: 0.9920 - output_2_acc: 0.9769 - output_3_acc: 0.9618 - val_loss: 0.5448 - val_output_1_loss: 0.0803 - val_output_2_loss: 0.2940 - val_output_3_loss: 0.5607 - val_output_1_acc: 0.9793 - val_output_2_acc: 0.9181 - val_output_3_acc: 0.8423\ncate1: 0.9647237568818763\ncate2: 0.8871895086216962\ncate3: 0.8125457227535522\ntotal: 0.8501566619268277\nEpoch 5/10\n140562/140562 [==============================] - 409s 3ms/step - loss: 0.1338 - output_1_loss: 0.0342 - output_2_loss: 0.0870 - output_3_loss: 0.1304 - output_1_acc: 0.9934 - output_2_acc: 0.9832 - output_3_acc: 0.9747 - val_loss: 0.5536 - val_output_1_loss: 0.0798 - val_output_2_loss: 0.2951 - val_output_3_loss: 0.5713 - val_output_1_acc: 0.9793 - val_output_2_acc: 0.9187 - val_output_3_acc: 0.8411\ncate1: 0.9644112965081446\ncate2: 0.8878653935903156\ncate3: 0.8111081796486231\ntotal: 0.849465655517083\n<keras.callbacks.History object at 0x7f88d9baf3c8>\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "czCE4Zo-GL8u",
        "colab_type": "code",
        "colab": {},
        "trusted": true,
        "_uuid": "452a5d7c1f0177c2c14e95a6f06cb4fa3f873d96",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "History = model.fit([val_X1,val_X2,val_X3,val_X4], [val_y1_hot,val_y2_hot,val_y3_hot], \n                    batch_size=64,\n                    epochs=START_EPOCH+EPOCH,                    \n                    shuffle=True, \n                    callbacks=[early_stopping,modelSave,getF1],\n                    validation_data=([val_X1,val_X2,val_X3,val_X4], [val_y1_hot,val_y2_hot,val_y3_hot]),\n#                     verbose=0,\n                    initial_epoch=START_EPOCH)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VWThi1E7LEvZ",
        "colab_type": "code",
        "colab": {},
        "trusted": true,
        "_uuid": "bf7d66fd87df01bd480cebff25db215d3139ad67"
      },
      "cell_type": "code",
      "source": "del model",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5Ocw6OPSwNVx",
        "colab_type": "text",
        "_uuid": "e0f618bc4c9409204a5c4e9a146b27f1e2d38730"
      },
      "cell_type": "markdown",
      "source": "# 3. 保存"
    },
    {
      "metadata": {
        "id": "iFJRuLM-0FJG",
        "colab_type": "code",
        "colab": {},
        "trusted": true,
        "_uuid": "a49af971bcdab660d9cb74b74088834ef1a8ba93"
      },
      "cell_type": "code",
      "source": "# !pip install -q pydot\n# # 画模型对应的结构图\n from keras.utils import plot_model\n plot_model(model, to_file='model.png')\n\n# from IPython.display import SVG\n# from keras.utils.vis_utils import model_to_dot\n\n# SVG(model_to_dot(model).create(prog='dot', format='svg'))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0NY5Bkqny46j",
        "colab_type": "code",
        "colab": {},
        "trusted": true,
        "_uuid": "889e9a330d0f9f7fe7b68cb2b28186eb9a39fdd9"
      },
      "cell_type": "code",
      "source": "# 预测结果并保存文件\npredictTest(model,'result2.txt')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c74Yp6AgKEhk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "08d8dd47-7cb9-44b8-f8c2-33cd9ef67a82",
        "trusted": true,
        "_uuid": "2b596003dd8b03aebfa83f92737475d500246699"
      },
      "cell_type": "code",
      "source": "!ls",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X9yNhHg-7vKB",
        "colab_type": "code",
        "colab": {},
        "trusted": true,
        "_uuid": "54cb386a385a283a99b49b7f39f9d160adf783a5"
      },
      "cell_type": "code",
      "source": "model.save('MyTest.h5')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C-_Eda95uZfM",
        "colab_type": "code",
        "colab": {},
        "trusted": true,
        "_uuid": "c26cdf465767596caa1371a51caa164493b33b86"
      },
      "cell_type": "code",
      "source": "# # 加载模型\n# from keras.models import load_model \n# model = load_model('model_old.hdf5')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vQaRKeHZcW4I",
        "colab_type": "code",
        "colab": {},
        "trusted": true,
        "_uuid": "f3b696361411f6d9857de50fbb21bd5cf3cfab92"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "v3_seedCup_NN.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU",
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}